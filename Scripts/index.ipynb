{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a449931-9a49-4028-96c6-a844464415a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des documents PDF…\n",
      "26 pages chargées.\n",
      "161 chunks créés.\n",
      "Génération de l'index FAISS…\n",
      "Index sauvegardé dans : embeddings/faiss_index\n"
     ]
    }
   ],
   "source": [
    "# construction d'index\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Chemin du dossier\n",
    "PDF_DIR = \"/home/sacko/Documents/Chatbot-Rh-Rag/Donnees\"\n",
    "\n",
    "# Chemin d'enregistrement de l’index FAISS\n",
    "INDEX_DIR = \"embeddings/faiss_index\"\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "# Modèle d'embedding\n",
    "MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "def charger_documents(pdf_dir):\n",
    "    print(\"Chargement des documents PDF…\")\n",
    "    \n",
    "    docs = []  # Liste qui contiendra toutes les pages extraites des fichiers PDF\n",
    "    for file in os.listdir(pdf_dir):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            chemin = os.path.join(pdf_dir, file)\n",
    "\n",
    "            # Chargeur LangChain spécialisé pour lire les PDF\n",
    "            loader = PyPDFLoader(chemin)\n",
    "            docs.extend(loader.load())\n",
    "    print(len(docs), \"pages chargées.\")\n",
    "    return docs\n",
    "\n",
    "# Création d'une fonction qui coupe les textes en morceaux\n",
    "def splitter_documents(docs):\n",
    "\n",
    "    # chunk_size=500 : chaque morceau fait environ 500 caractères\n",
    "    # chunk_overlap=50 : 50 caractères se chevauchent entre deux chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    textes = splitter.split_documents(docs)\n",
    "    print(len(textes), \"chunks créés.\")\n",
    "    return textes\n",
    "\n",
    "def construire_index(textes, model_name, index_dir):\n",
    "    print(\"Génération de l'index FAISS…\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    db = FAISS.from_documents(textes, embeddings)\n",
    "    db.save_local(index_dir)\n",
    "    print(\"Index sauvegardé dans :\", index_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docs = charger_documents(PDF_DIR)\n",
    "    textes = splitter_documents(docs)\n",
    "    construire_index(textes, MODEL, INDEX_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ce35e-2779-4536-98be-fc0b54c168ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Projet_rag_rh)",
   "language": "python",
   "name": "projet_rag_rh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
