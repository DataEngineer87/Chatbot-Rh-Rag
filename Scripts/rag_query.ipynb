{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a792fe-805c-4fb1-9f7f-a7fdd2dabcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Chemin FAISS\n",
    "INDEX_DIR = \"embeddings/faiss_index\"\n",
    "\n",
    "# Modèle d'embedding\n",
    "MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# Mots clés pour vérifier la nature RH de la question\n",
    "KEYWORDS_RH = [\n",
    "    \"rh\", \"ressources humaines\", \"télétravail\", \"teletravail\", \"congé\", \"conges\",\n",
    "    \"absence\", \"salaire\", \"contrat\", \"formation\", \"recrutement\",\n",
    "    \"employé\", \"collaborateur\", \"procédure\", \"politique\", \"rémunération\",\n",
    "    \"remuneration\", \"absence\", \"convention\", \"accord\", \"document interne\"\n",
    "]\n",
    "\n",
    "# Prompt système renforcé\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Tu es un assistant RH interne.\n",
    "Tu réponds strictement à partir des documents internes fournis dans le contexte.\n",
    "Si les documents permettent d’apporter une réponse, tu dois répondre clairement.\n",
    "\n",
    "Si la réponse ne se trouve pas dans les documents internes RH,\n",
    "réponds exactement :\n",
    "\"Je ne peux répondre qu’aux questions liées aux documents internes RH.\"\n",
    "\"\"\"\n",
    "\n",
    "# Charge l’index FAISS\n",
    "def charger_retriever():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=MODEL)\n",
    "    db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}\n",
    "    )\n",
    "    return retriever\n",
    "\n",
    "# Détection basique domaine RH\n",
    "def question_concerne_rh(question):\n",
    "    q = question.lower()\n",
    "    return any(keyword in q for keyword in KEYWORDS_RH)\n",
    "\n",
    "# Pipeline RAG complet.\n",
    "def repondre(question):\n",
    "\n",
    "    # Vérifier domaine RH\n",
    "    if not question_concerne_rh(question):\n",
    "        return \"Je ne peux répondre qu’aux questions liées aux documents internes RH.\"\n",
    "\n",
    "    # Charger FAISS\n",
    "    try:\n",
    "        retriever = charger_retriever()\n",
    "    except Exception as e:\n",
    "        return \"Erreur interne : impossible de charger les documents.\"\n",
    "\n",
    "    # Récupération des documents pertinents\n",
    "    try:\n",
    "        docs = retriever.invoke(question)\n",
    "    except Exception:\n",
    "        return \"Je ne peux répondre qu’aux questions liées aux documents internes RH.\"\n",
    "\n",
    "    # Aucun document trouvé\n",
    "    if not docs or len(docs) == 0:\n",
    "        return \"Je ne peux répondre qu’aux questions liées aux documents internes RH.\"\n",
    "\n",
    "    # Construction du contexte\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Appel LLM avec prompt système + contexte\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Contexte:\\n{context}\\n\\nQuestion:\\n{question}\"}\n",
    "    ]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "    try:\n",
    "        answer = llm.invoke(messages)\n",
    "        return answer.content\n",
    "    except Exception:\n",
    "        return \"Erreur interne : impossible de générer une réponse.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac646d1a-4a93-4f99-8584-04b333176c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Projet_rag_rh)",
   "language": "python",
   "name": "projet_rag_rh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
